{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "floppy-accident",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import dependencies\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from datetime import datetime\n",
    "import requests\n",
    "import pandas_datareader as pdr\n",
    "from datetime import datetime\n",
    "import pandas_datareader as pdr\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "import warnings\n",
    "import hvplot.pandas\n",
    "from keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM\n",
    "from keras.layers import Dense, Dropout\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
    "%matplotlib inline\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "fossil-species",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Function to Validate Tickers\n",
    "def validateTick(tick):\n",
    "    \n",
    "    # Try Inputting into Yahoo Stocks\n",
    "    try:\n",
    "        pdr.DataReader(f'{tick}','yahoo',date)\n",
    "    \n",
    "    # Raise Error if Invalid\n",
    "    except:\n",
    "        raise ValueError(\"Ticker Not Valid.\")\n",
    "        \n",
    "# Function to Validate Date\n",
    "def validate(date_text):\n",
    "    \n",
    "    # Try Check on Format\n",
    "    try:\n",
    "        datetime.strptime(date_text, '%Y-%m-%d')\n",
    "        \n",
    "    # Raise Error if Invalid\n",
    "    except ValueError:\n",
    "        raise ValueError(\"Incorrect data format, should be YYYY-MM-DD\")\n",
    "        \n",
    "# Function to Validate Date\n",
    "def validateShift(shift):\n",
    "    shift = int(shift)\n",
    "    # Try Check on Format\n",
    "    try:\n",
    "        if 0 > shift <= 365:\n",
    "            pass\n",
    "        \n",
    "    # Raise Error if Invalid\n",
    "    except ValueError:\n",
    "        raise ValueError(\"Please enter a whole number.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "opening-wrapping",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Pick a start date for your analysis (YYYY-MM-DD):  2016-01-01\n"
     ]
    }
   ],
   "source": [
    "# Pick a Start Date\n",
    "date = input(\"Pick a start date for your analysis (YYYY-MM-DD): \")\n",
    "\n",
    "# Validate Correct Date Format\n",
    "validate(date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "identical-airline",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Pick a stock ticker for your analysis:  CME\n"
     ]
    }
   ],
   "source": [
    "# Pick a Stock\n",
    "stock_selection = input(\"Pick a stock ticker for your analysis: \")\n",
    "\n",
    "# Validate Correct Date Format\n",
    "validateTick(stock_selection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "judicial-energy",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Pick how many days to shift your close values for your analysis:  1\n"
     ]
    }
   ],
   "source": [
    "# Pick Shift\n",
    "shift_selection = input(\"Pick how many days to shift your close values for your analysis: \")\n",
    "\n",
    "# Validate Correct Date Format\n",
    "validateShift(shift_selection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "mathematical-prerequisite",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Function to Create Stocks\n",
    "def stockCreation(date, stock_selection, days_shifted):\n",
    "    \n",
    "    # Read Stock Data\n",
    "    globals()[stock_selection] = pdr.DataReader(f'{stock_selection}','yahoo',date)\n",
    "    \n",
    "    # Create Shifted Close Column\n",
    "    globals()[stock_selection][\"Shifted Close\"] = globals()[stock_selection][\"Adj Close\"].shift(-int(days_shifted))\n",
    "    \n",
    "    # Drop Rows Without Shift Values\n",
    "    globals()[stock_selection].drop(globals()[stock_selection].tail(int(days_shifted)).index, inplace = True) \n",
    "    \n",
    "    # Empty List to Hold Profit or Loss\n",
    "    profit_loss = []\n",
    "    \n",
    "    # Iterate Through DataFrame\n",
    "    for x in range(len(globals()[stock_selection])):\n",
    "        \n",
    "        # Handle Profitable Days\n",
    "        if globals()[stock_selection][\"Shifted Close\"][x] > globals()[stock_selection][\"Adj Close\"][x]:\n",
    "            \n",
    "            # Append \"Profit\" to Empty List\n",
    "            profit_loss.append(\"Profit\")\n",
    "            \n",
    "        # Handle Loss Days\n",
    "        elif globals()[stock_selection][\"Shifted Close\"][x] < globals()[stock_selection][\"Adj Close\"][x]:\n",
    "            \n",
    "            # Append \"Loss\" to Empty List\n",
    "            profit_loss.append(\"Loss\")\n",
    "            \n",
    "        # Handle Push Days\n",
    "        elif globals()[stock_selection][\"Shifted Close\"][x] == globals()[stock_selection][\"Adj Close\"][x]:\n",
    "            \n",
    "            # Append \"Push\" to Empty List\n",
    "            profit_loss.append(\"Push\")\n",
    "    \n",
    "    # Create Profit/Loss Column\n",
    "    globals()[stock_selection][\"Profit/Loss\"] = profit_loss\n",
    "    \n",
    "    # Create Returns Column\n",
    "    globals()[stock_selection]['Returns'] = np.log(globals()[stock_selection]['Adj Close'] / globals()[stock_selection]['Adj Close'].shift(1))\n",
    "    \n",
    "    # Iterate to Create STD Columns\n",
    "    for x in range(5, 20, 5):\n",
    "        \n",
    "        # Create STD Column Based on Iteration\n",
    "        col_name = 'std_' + str(x)\n",
    "        \n",
    "        # Add STD Column to DataFrame\n",
    "        globals()[stock_selection][col_name] = globals()[stock_selection]['Adj Close'].rolling(window=x).std()\n",
    "\n",
    "    # Iterate to Create MA Columns\n",
    "    for x in range(10, 30, 5):\n",
    "        \n",
    "        # Create MA Column Based on Iteration\n",
    "        col_name = 'ma_' + str(x)\n",
    "        \n",
    "        # Add MA Column to DataFrame\n",
    "        globals()[stock_selection][col_name] = globals()[stock_selection]['Adj Close'].rolling(window=x).mean()\n",
    "\n",
    "    # Iterate to Create % Change Columns\n",
    "    for x in range(3, 12, 3):\n",
    "        \n",
    "        # Create % Change Column Based on Iteration\n",
    "        col_name = 'pct_' + str(x)\n",
    "        \n",
    "        # Add % Change Column to DataFrame\n",
    "        globals()[stock_selection][col_name] = globals()[stock_selection]['Adj Close'].pct_change().rolling(window=x).sum()\n",
    "\n",
    "    # Create VMA 4 Column\n",
    "    col_name = 'vma_4'\n",
    "    \n",
    "    # Add VMA 4 Column to DataFrame\n",
    "    globals()[stock_selection][col_name] = globals()[stock_selection]['Volume'].rolling(4).mean()\n",
    "\n",
    "    # Create Intraday Column\n",
    "    col_name = 'co'\n",
    "    \n",
    "    # Add Intraday Column to DataFrame\n",
    "    globals()[stock_selection][col_name] = globals()[stock_selection]['Adj Close'] - globals()[stock_selection]['Open']\n",
    "    \n",
    "    # Drop All NaN's\n",
    "    globals()[stock_selection].dropna(inplace=True)\n",
    "    \n",
    "    # Return DataFrame\n",
    "    return globals()[stock_selection]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "final-campaign",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Open</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Shifted Close</th>\n",
       "      <th>Profit/Loss</th>\n",
       "      <th>Returns</th>\n",
       "      <th>std_5</th>\n",
       "      <th>...</th>\n",
       "      <th>std_15</th>\n",
       "      <th>ma_10</th>\n",
       "      <th>ma_15</th>\n",
       "      <th>ma_20</th>\n",
       "      <th>ma_25</th>\n",
       "      <th>pct_3</th>\n",
       "      <th>pct_6</th>\n",
       "      <th>pct_9</th>\n",
       "      <th>vma_4</th>\n",
       "      <th>co</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2016-02-08</th>\n",
       "      <td>90.669998</td>\n",
       "      <td>87.000000</td>\n",
       "      <td>88.410004</td>\n",
       "      <td>90.190002</td>\n",
       "      <td>2758100.0</td>\n",
       "      <td>75.330887</td>\n",
       "      <td>77.936836</td>\n",
       "      <td>Profit</td>\n",
       "      <td>0.018351</td>\n",
       "      <td>1.218740</td>\n",
       "      <td>...</td>\n",
       "      <td>2.022289</td>\n",
       "      <td>73.756442</td>\n",
       "      <td>72.653080</td>\n",
       "      <td>72.354897</td>\n",
       "      <td>72.608648</td>\n",
       "      <td>0.009896</td>\n",
       "      <td>0.004898</td>\n",
       "      <td>0.044908</td>\n",
       "      <td>2910525.0</td>\n",
       "      <td>-13.079117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-02-09</th>\n",
       "      <td>93.809998</td>\n",
       "      <td>89.050003</td>\n",
       "      <td>89.050003</td>\n",
       "      <td>93.309998</td>\n",
       "      <td>3233500.0</td>\n",
       "      <td>77.936836</td>\n",
       "      <td>75.614868</td>\n",
       "      <td>Loss</td>\n",
       "      <td>0.034008</td>\n",
       "      <td>2.126921</td>\n",
       "      <td>...</td>\n",
       "      <td>2.423534</td>\n",
       "      <td>74.336102</td>\n",
       "      <td>73.053999</td>\n",
       "      <td>72.620506</td>\n",
       "      <td>72.763668</td>\n",
       "      <td>0.078829</td>\n",
       "      <td>0.044054</td>\n",
       "      <td>0.075449</td>\n",
       "      <td>3200800.0</td>\n",
       "      <td>-11.113167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-02-10</th>\n",
       "      <td>93.489998</td>\n",
       "      <td>90.440002</td>\n",
       "      <td>93.029999</td>\n",
       "      <td>90.529999</td>\n",
       "      <td>2133700.0</td>\n",
       "      <td>75.614868</td>\n",
       "      <td>74.604225</td>\n",
       "      <td>Loss</td>\n",
       "      <td>-0.030246</td>\n",
       "      <td>2.154174</td>\n",
       "      <td>...</td>\n",
       "      <td>2.382844</td>\n",
       "      <td>74.654331</td>\n",
       "      <td>73.406474</td>\n",
       "      <td>72.757486</td>\n",
       "      <td>72.802423</td>\n",
       "      <td>0.023321</td>\n",
       "      <td>0.017951</td>\n",
       "      <td>0.041389</td>\n",
       "      <td>2785025.0</td>\n",
       "      <td>-17.415131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-02-11</th>\n",
       "      <td>90.550003</td>\n",
       "      <td>88.320000</td>\n",
       "      <td>88.360001</td>\n",
       "      <td>89.320000</td>\n",
       "      <td>1952800.0</td>\n",
       "      <td>74.604225</td>\n",
       "      <td>76.132721</td>\n",
       "      <td>Profit</td>\n",
       "      <td>-0.013456</td>\n",
       "      <td>1.512457</td>\n",
       "      <td>...</td>\n",
       "      <td>1.967143</td>\n",
       "      <td>74.840592</td>\n",
       "      <td>73.814632</td>\n",
       "      <td>72.972562</td>\n",
       "      <td>72.815453</td>\n",
       "      <td>-0.008565</td>\n",
       "      <td>0.001331</td>\n",
       "      <td>-0.003668</td>\n",
       "      <td>2519525.0</td>\n",
       "      <td>-13.755775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-02-12</th>\n",
       "      <td>91.290001</td>\n",
       "      <td>89.510002</td>\n",
       "      <td>90.919998</td>\n",
       "      <td>91.150002</td>\n",
       "      <td>1691200.0</td>\n",
       "      <td>76.132721</td>\n",
       "      <td>75.765213</td>\n",
       "      <td>Loss</td>\n",
       "      <td>0.020281</td>\n",
       "      <td>1.253418</td>\n",
       "      <td>...</td>\n",
       "      <td>1.863000</td>\n",
       "      <td>74.949174</td>\n",
       "      <td>74.169889</td>\n",
       "      <td>73.241928</td>\n",
       "      <td>72.936396</td>\n",
       "      <td>-0.022671</td>\n",
       "      <td>0.056159</td>\n",
       "      <td>0.021383</td>\n",
       "      <td>2252800.0</td>\n",
       "      <td>-14.787277</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 High        Low       Open      Close     Volume  Adj Close  \\\n",
       "Date                                                                           \n",
       "2016-02-08  90.669998  87.000000  88.410004  90.190002  2758100.0  75.330887   \n",
       "2016-02-09  93.809998  89.050003  89.050003  93.309998  3233500.0  77.936836   \n",
       "2016-02-10  93.489998  90.440002  93.029999  90.529999  2133700.0  75.614868   \n",
       "2016-02-11  90.550003  88.320000  88.360001  89.320000  1952800.0  74.604225   \n",
       "2016-02-12  91.290001  89.510002  90.919998  91.150002  1691200.0  76.132721   \n",
       "\n",
       "            Shifted Close Profit/Loss   Returns     std_5  ...    std_15  \\\n",
       "Date                                                       ...             \n",
       "2016-02-08      77.936836      Profit  0.018351  1.218740  ...  2.022289   \n",
       "2016-02-09      75.614868        Loss  0.034008  2.126921  ...  2.423534   \n",
       "2016-02-10      74.604225        Loss -0.030246  2.154174  ...  2.382844   \n",
       "2016-02-11      76.132721      Profit -0.013456  1.512457  ...  1.967143   \n",
       "2016-02-12      75.765213        Loss  0.020281  1.253418  ...  1.863000   \n",
       "\n",
       "                ma_10      ma_15      ma_20      ma_25     pct_3     pct_6  \\\n",
       "Date                                                                         \n",
       "2016-02-08  73.756442  72.653080  72.354897  72.608648  0.009896  0.004898   \n",
       "2016-02-09  74.336102  73.053999  72.620506  72.763668  0.078829  0.044054   \n",
       "2016-02-10  74.654331  73.406474  72.757486  72.802423  0.023321  0.017951   \n",
       "2016-02-11  74.840592  73.814632  72.972562  72.815453 -0.008565  0.001331   \n",
       "2016-02-12  74.949174  74.169889  73.241928  72.936396 -0.022671  0.056159   \n",
       "\n",
       "               pct_9      vma_4         co  \n",
       "Date                                        \n",
       "2016-02-08  0.044908  2910525.0 -13.079117  \n",
       "2016-02-09  0.075449  3200800.0 -11.113167  \n",
       "2016-02-10  0.041389  2785025.0 -17.415131  \n",
       "2016-02-11 -0.003668  2519525.0 -13.755775  \n",
       "2016-02-12  0.021383  2252800.0 -14.787277  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create Stock\n",
    "stockdf = stockCreation(date, stock_selection, shift_selection)\n",
    "stockdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "dangerous-toner",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method DataFrame.info of                   High         Low        Open       Close     Volume  \\\n",
       "Date                                                                    \n",
       "2016-02-08   90.669998   87.000000   88.410004   90.190002  2758100.0   \n",
       "2016-02-09   93.809998   89.050003   89.050003   93.309998  3233500.0   \n",
       "2016-02-10   93.489998   90.440002   93.029999   90.529999  2133700.0   \n",
       "2016-02-11   90.550003   88.320000   88.360001   89.320000  1952800.0   \n",
       "2016-02-12   91.290001   89.510002   90.919998   91.150002  1691200.0   \n",
       "...                ...         ...         ...         ...        ...   \n",
       "2021-02-12  184.589996  182.110001  182.860001  184.369995  1441400.0   \n",
       "2021-02-16  189.899994  183.000000  185.089996  189.410004  2677700.0   \n",
       "2021-02-17  191.899994  187.220001  189.419998  191.139999  1513800.0   \n",
       "2021-02-18  194.240005  189.720001  190.050003  193.990005  1497200.0   \n",
       "2021-02-19  196.460007  192.889999  194.970001  195.070007  1419300.0   \n",
       "\n",
       "             Adj Close  Shifted Close Profit/Loss   Returns     std_5  ...  \\\n",
       "Date                                                                   ...   \n",
       "2016-02-08   75.330887      77.936836      Profit  0.018351  1.218740  ...   \n",
       "2016-02-09   77.936836      75.614868        Loss  0.034008  2.126921  ...   \n",
       "2016-02-10   75.614868      74.604225        Loss -0.030246  2.154174  ...   \n",
       "2016-02-11   74.604225      76.132721      Profit -0.013456  1.512457  ...   \n",
       "2016-02-12   76.132721      75.765213        Loss  0.020281  1.253418  ...   \n",
       "...                ...            ...         ...       ...       ...  ...   \n",
       "2021-02-12  184.369995     189.410004      Profit  0.009044  4.345501  ...   \n",
       "2021-02-16  189.410004     191.139999      Profit  0.026969  3.831152  ...   \n",
       "2021-02-17  191.139999     193.990005      Profit  0.009092  3.555521  ...   \n",
       "2021-02-18  193.990005     195.070007      Profit  0.014800  4.700105  ...   \n",
       "2021-02-19  195.070007     193.059998        Loss  0.005552  4.236793  ...   \n",
       "\n",
       "              std_15       ma_10       ma_15       ma_20       ma_25  \\\n",
       "Date                                                                   \n",
       "2016-02-08  2.022289   73.756442   72.653080   72.354897   72.608648   \n",
       "2016-02-09  2.423534   74.336102   73.053999   72.620506   72.763668   \n",
       "2016-02-10  2.382844   74.654331   73.406474   72.757486   72.802423   \n",
       "2016-02-11  1.967143   74.840592   73.814632   72.972562   72.815453   \n",
       "2016-02-12  1.863000   74.949174   74.169889   73.241928   72.936396   \n",
       "...              ...         ...         ...         ...         ...   \n",
       "2021-02-12  4.786531  189.235001  186.898000  187.378000  189.590400   \n",
       "2021-02-16  4.773276  189.432001  187.234001  187.257500  189.179600   \n",
       "2021-02-17  4.769367  189.345001  187.726667  187.204500  188.867600   \n",
       "2021-02-18  4.329455  189.545001  188.740001  187.412500  188.567600   \n",
       "2021-02-19  4.247610  189.699002  189.580002  187.856001  188.452401   \n",
       "\n",
       "               pct_3     pct_6     pct_9      vma_4         co  \n",
       "Date                                                            \n",
       "2016-02-08  0.009896  0.004898  0.044908  2910525.0 -13.079117  \n",
       "2016-02-09  0.078829  0.044054  0.075449  3200800.0 -11.113167  \n",
       "2016-02-10  0.023321  0.017951  0.041389  2785025.0 -17.415131  \n",
       "2016-02-11 -0.008565  0.001331 -0.003668  2519525.0 -13.755775  \n",
       "2016-02-12 -0.022671  0.056159  0.021383  2252800.0 -14.787277  \n",
       "...              ...       ...       ...        ...        ...  \n",
       "2021-02-12 -0.039625 -0.047655 -0.015357  2167750.0   1.509995  \n",
       "2021-02-16  0.022977 -0.009261 -0.012401  2330600.0   4.320007  \n",
       "2021-02-17  0.045555 -0.001956 -0.003164  2036975.0   1.720001  \n",
       "2021-02-18  0.051381  0.011755  0.003726  1782525.0   3.940002  \n",
       "2021-02-19  0.029611  0.052588  0.020351  1777000.0   0.100006  \n",
       "\n",
       "[1268 rows x 21 columns]>"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stockdf.info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "cooperative-oracle",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create function for column numbering including features (X) and target (y)\n",
    "def window_data(df, window, feature_column, target_column):\n",
    "    X = []\n",
    "    y = []\n",
    "    for i in range(len(df) - window):\n",
    "        features = df.iloc[i : (i + window), feature_column]\n",
    "        target = df.iloc[(i + window), target_column]\n",
    "        X.append(features)\n",
    "        y.append(target)\n",
    "    return np.array(X), np.array(y).reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "abandoned-slave",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # change profit/loss to 0's/1's\n",
    "# ## convert from string to integer\n",
    "profit_loss = []\n",
    "for row in stockdf.iloc[:,7]:\n",
    "    if row == 'Loss':\n",
    "         profit_loss.append(0)\n",
    "    else:\n",
    "         profit_loss.append(1)\n",
    "            \n",
    "stockdf [\"Profit/Loss\"] = profit_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "olympic-tiger",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X sample values:\n",
      "[[1 0 0 1 0 1 0 1 0 0 1 1 0 0 1 1 1 1 0 1 1 0 1 1 1 0 1 0 0 0 1 0 1 0 1 1\n",
      "  1 0 0 0 0 0 1 1 1 1 1 1 1 1 0 1 0 1 1 0 0 1 0 0 1 0 1 1 0 1 0 1 0 1 0 1\n",
      "  1 1 0 0 1 0 1 0 0 0 0 0 0 1 1 0 0 1 0 0 0 1 1 1 0 1 1 1]\n",
      " [0 0 1 0 1 0 1 0 0 1 1 0 0 1 1 1 1 0 1 1 0 1 1 1 0 1 0 0 0 1 0 1 0 1 1 1\n",
      "  0 0 0 0 0 1 1 1 1 1 1 1 1 0 1 0 1 1 0 0 1 0 0 1 0 1 1 0 1 0 1 0 1 0 1 1\n",
      "  1 0 0 1 0 1 0 0 0 0 0 0 1 1 0 0 1 0 0 0 1 1 1 0 1 1 1 0]\n",
      " [0 1 0 1 0 1 0 0 1 1 0 0 1 1 1 1 0 1 1 0 1 1 1 0 1 0 0 0 1 0 1 0 1 1 1 0\n",
      "  0 0 0 0 1 1 1 1 1 1 1 1 0 1 0 1 1 0 0 1 0 0 1 0 1 1 0 1 0 1 0 1 0 1 1 1\n",
      "  0 0 1 0 1 0 0 0 0 0 0 1 1 0 0 1 0 0 0 1 1 1 0 1 1 1 0 1]\n",
      " [1 0 1 0 1 0 0 1 1 0 0 1 1 1 1 0 1 1 0 1 1 1 0 1 0 0 0 1 0 1 0 1 1 1 0 0\n",
      "  0 0 0 1 1 1 1 1 1 1 1 0 1 0 1 1 0 0 1 0 0 1 0 1 1 0 1 0 1 0 1 0 1 1 1 0\n",
      "  0 1 0 1 0 0 0 0 0 0 1 1 0 0 1 0 0 0 1 1 1 0 1 1 1 0 1 1]\n",
      " [0 1 0 1 0 0 1 1 0 0 1 1 1 1 0 1 1 0 1 1 1 0 1 0 0 0 1 0 1 0 1 1 1 0 0 0\n",
      "  0 0 1 1 1 1 1 1 1 1 0 1 0 1 1 0 0 1 0 0 1 0 1 1 0 1 0 1 0 1 0 1 1 1 0 0\n",
      "  1 0 1 0 0 0 0 0 0 1 1 0 0 1 0 0 0 1 1 1 0 1 1 1 0 1 1 1]] \n",
      "\n",
      "y sample values:\n",
      "[[95.90000153]\n",
      " [96.01000214]\n",
      " [95.59999847]\n",
      " [97.61000061]\n",
      " [97.29000092]]\n"
     ]
    }
   ],
   "source": [
    "# Predict Closing Prices\n",
    "window_size = 100\n",
    "\n",
    "feature_column = 7\n",
    "target_column = 1\n",
    "X, y = window_data(stockdf, window_size, feature_column, target_column)\n",
    "print (f\"X sample values:\\n{X[:5]} \\n\")\n",
    "print (f\"y sample values:\\n{y[:5]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "handled-vertical",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use 70% of the data for training and the remainder for testing\n",
    "split = int(0.7 * len(X))\n",
    "X_train = X[: split]\n",
    "X_test = X[split:]\n",
    "y_train = y[: split]\n",
    "y_test = y[split:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "clean-beach",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0., 1., 0., 1., 0., 1., 0., 0., 1., 1., 0., 0., 1., 1.,\n",
       "        1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 1., 0., 0., 0., 1., 0.,\n",
       "        1., 0., 1., 1., 1., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 0., 1., 0., 1., 1., 0., 0., 1., 0., 0., 1., 0., 1., 1.,\n",
       "        0., 1., 0., 1., 0., 1., 0., 1., 1., 1., 0., 0., 1., 0., 1., 0.,\n",
       "        0., 0., 0., 0., 0., 1., 1., 0., 0., 1., 0., 0., 0., 1., 1., 1.,\n",
       "        0., 1., 1., 1.],\n",
       "       [0., 0., 1., 0., 1., 0., 1., 0., 0., 1., 1., 0., 0., 1., 1., 1.,\n",
       "        1., 0., 1., 1., 0., 1., 1., 1., 0., 1., 0., 0., 0., 1., 0., 1.,\n",
       "        0., 1., 1., 1., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 0., 1., 0., 1., 1., 0., 0., 1., 0., 0., 1., 0., 1., 1., 0.,\n",
       "        1., 0., 1., 0., 1., 0., 1., 1., 1., 0., 0., 1., 0., 1., 0., 0.,\n",
       "        0., 0., 0., 0., 1., 1., 0., 0., 1., 0., 0., 0., 1., 1., 1., 0.,\n",
       "        1., 1., 1., 0.],\n",
       "       [0., 1., 0., 1., 0., 1., 0., 0., 1., 1., 0., 0., 1., 1., 1., 1.,\n",
       "        0., 1., 1., 0., 1., 1., 1., 0., 1., 0., 0., 0., 1., 0., 1., 0.,\n",
       "        1., 1., 1., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        0., 1., 0., 1., 1., 0., 0., 1., 0., 0., 1., 0., 1., 1., 0., 1.,\n",
       "        0., 1., 0., 1., 0., 1., 1., 1., 0., 0., 1., 0., 1., 0., 0., 0.,\n",
       "        0., 0., 0., 1., 1., 0., 0., 1., 0., 0., 0., 1., 1., 1., 0., 1.,\n",
       "        1., 1., 0., 1.],\n",
       "       [1., 0., 1., 0., 1., 0., 0., 1., 1., 0., 0., 1., 1., 1., 1., 0.,\n",
       "        1., 1., 0., 1., 1., 1., 0., 1., 0., 0., 0., 1., 0., 1., 0., 1.,\n",
       "        1., 1., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0.,\n",
       "        1., 0., 1., 1., 0., 0., 1., 0., 0., 1., 0., 1., 1., 0., 1., 0.,\n",
       "        1., 0., 1., 0., 1., 1., 1., 0., 0., 1., 0., 1., 0., 0., 0., 0.,\n",
       "        0., 0., 1., 1., 0., 0., 1., 0., 0., 0., 1., 1., 1., 0., 1., 1.,\n",
       "        1., 0., 1., 1.],\n",
       "       [0., 1., 0., 1., 0., 0., 1., 1., 0., 0., 1., 1., 1., 1., 0., 1.,\n",
       "        1., 0., 1., 1., 1., 0., 1., 0., 0., 0., 1., 0., 1., 0., 1., 1.,\n",
       "        1., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1.,\n",
       "        0., 1., 1., 0., 0., 1., 0., 0., 1., 0., 1., 1., 0., 1., 0., 1.,\n",
       "        0., 1., 0., 1., 1., 1., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0.,\n",
       "        0., 1., 1., 0., 0., 1., 0., 0., 0., 1., 1., 1., 0., 1., 1., 1.,\n",
       "        0., 1., 1., 1.]])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use the MinMaxScaler to scale data between 0 and 1.\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(X)\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "scaler.fit(y)\n",
    "y_train = scaler.transform(y_train)\n",
    "y_test = scaler.transform(y_test)\n",
    "X_train[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "surgical-distributor",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train sample values:\n",
      "[[[1.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [1.]\n",
      "  [0.]\n",
      "  [1.]\n",
      "  [0.]\n",
      "  [1.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [0.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [0.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [0.]\n",
      "  [1.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [1.]\n",
      "  [0.]\n",
      "  [1.]\n",
      "  [0.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [0.]\n",
      "  [1.]\n",
      "  [0.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [1.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [1.]\n",
      "  [0.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [0.]\n",
      "  [1.]\n",
      "  [0.]\n",
      "  [1.]\n",
      "  [0.]\n",
      "  [1.]\n",
      "  [0.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [1.]\n",
      "  [0.]\n",
      "  [1.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [1.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [0.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [1.]]\n",
      "\n",
      " [[0.]\n",
      "  [0.]\n",
      "  [1.]\n",
      "  [0.]\n",
      "  [1.]\n",
      "  [0.]\n",
      "  [1.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [0.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [0.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [0.]\n",
      "  [1.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [1.]\n",
      "  [0.]\n",
      "  [1.]\n",
      "  [0.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [0.]\n",
      "  [1.]\n",
      "  [0.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [1.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [1.]\n",
      "  [0.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [0.]\n",
      "  [1.]\n",
      "  [0.]\n",
      "  [1.]\n",
      "  [0.]\n",
      "  [1.]\n",
      "  [0.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [1.]\n",
      "  [0.]\n",
      "  [1.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [1.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [0.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [0.]]\n",
      "\n",
      " [[0.]\n",
      "  [1.]\n",
      "  [0.]\n",
      "  [1.]\n",
      "  [0.]\n",
      "  [1.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [0.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [0.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [0.]\n",
      "  [1.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [1.]\n",
      "  [0.]\n",
      "  [1.]\n",
      "  [0.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [0.]\n",
      "  [1.]\n",
      "  [0.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [1.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [1.]\n",
      "  [0.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [0.]\n",
      "  [1.]\n",
      "  [0.]\n",
      "  [1.]\n",
      "  [0.]\n",
      "  [1.]\n",
      "  [0.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [1.]\n",
      "  [0.]\n",
      "  [1.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [1.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [0.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [0.]\n",
      "  [1.]]\n",
      "\n",
      " [[1.]\n",
      "  [0.]\n",
      "  [1.]\n",
      "  [0.]\n",
      "  [1.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [0.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [0.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [0.]\n",
      "  [1.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [1.]\n",
      "  [0.]\n",
      "  [1.]\n",
      "  [0.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [0.]\n",
      "  [1.]\n",
      "  [0.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [1.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [1.]\n",
      "  [0.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [0.]\n",
      "  [1.]\n",
      "  [0.]\n",
      "  [1.]\n",
      "  [0.]\n",
      "  [1.]\n",
      "  [0.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [1.]\n",
      "  [0.]\n",
      "  [1.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [1.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [0.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [0.]\n",
      "  [1.]\n",
      "  [1.]]\n",
      "\n",
      " [[0.]\n",
      "  [1.]\n",
      "  [0.]\n",
      "  [1.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [0.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [0.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [0.]\n",
      "  [1.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [1.]\n",
      "  [0.]\n",
      "  [1.]\n",
      "  [0.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [0.]\n",
      "  [1.]\n",
      "  [0.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [1.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [1.]\n",
      "  [0.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [0.]\n",
      "  [1.]\n",
      "  [0.]\n",
      "  [1.]\n",
      "  [0.]\n",
      "  [1.]\n",
      "  [0.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [1.]\n",
      "  [0.]\n",
      "  [1.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [1.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [0.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [0.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [1.]]] \n",
      "\n",
      "X_test sample values:\n",
      "[[[1.]\n",
      "  [1.]\n",
      "  [0.]\n",
      "  [1.]\n",
      "  [0.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [0.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [0.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [0.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [0.]\n",
      "  [1.]\n",
      "  [0.]\n",
      "  [1.]\n",
      "  [0.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [0.]\n",
      "  [1.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [0.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [0.]\n",
      "  [1.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [1.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [0.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [0.]\n",
      "  [1.]\n",
      "  [0.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [0.]\n",
      "  [0.]]\n",
      "\n",
      " [[1.]\n",
      "  [0.]\n",
      "  [1.]\n",
      "  [0.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [0.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [0.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [0.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [0.]\n",
      "  [1.]\n",
      "  [0.]\n",
      "  [1.]\n",
      "  [0.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [0.]\n",
      "  [1.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [0.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [0.]\n",
      "  [1.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [1.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [0.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [0.]\n",
      "  [1.]\n",
      "  [0.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]]\n",
      "\n",
      " [[0.]\n",
      "  [1.]\n",
      "  [0.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [0.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [0.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [0.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [0.]\n",
      "  [1.]\n",
      "  [0.]\n",
      "  [1.]\n",
      "  [0.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [0.]\n",
      "  [1.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [0.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [0.]\n",
      "  [1.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [1.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [0.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [0.]\n",
      "  [1.]\n",
      "  [0.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]]\n",
      "\n",
      " [[1.]\n",
      "  [0.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [0.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [0.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [0.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [0.]\n",
      "  [1.]\n",
      "  [0.]\n",
      "  [1.]\n",
      "  [0.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [0.]\n",
      "  [1.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [0.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [0.]\n",
      "  [1.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [1.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [0.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [0.]\n",
      "  [1.]\n",
      "  [0.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [1.]]\n",
      "\n",
      " [[0.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [0.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [0.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [0.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [0.]\n",
      "  [1.]\n",
      "  [0.]\n",
      "  [1.]\n",
      "  [0.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [0.]\n",
      "  [1.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [0.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [0.]\n",
      "  [1.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [1.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [0.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [0.]\n",
      "  [1.]\n",
      "  [0.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [1.]\n",
      "  [1.]]] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Reshape the features for the model\n",
    "X_train = X_train.reshape((X_train.shape[0], X_train.shape[1], 1))\n",
    "X_test = X_test.reshape((X_test.shape[0], X_test.shape[1], 1))\n",
    "print (f\"X_train sample values:\\n{X_train[:5]} \\n\")\n",
    "print (f\"X_test sample values:\\n{X_test[:5]} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "mobile-warner",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the LSTM model. \n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "number_units = 50\n",
    "dropout_fraction = 0.2\n",
    "\n",
    "# Layer 1\n",
    "model.add(LSTM(\n",
    "    units=number_units,\n",
    "    return_sequences=True,\n",
    "    input_shape=(X_train.shape[1], 1))\n",
    "    )\n",
    "model.add(Dropout(dropout_fraction))\n",
    "\n",
    "# Layer 2\n",
    "model.add(LSTM(units=number_units, return_sequences=True))\n",
    "model.add(Dropout(dropout_fraction))\n",
    "\n",
    "# Layer 3\n",
    "model.add(LSTM(units=number_units))\n",
    "model.add(Dropout(dropout_fraction))\n",
    "\n",
    "# Output layer\n",
    "model.add(Dense(1,activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "medium-owner",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "greek-cradle",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_6 (LSTM)                (None, 100, 50)           10400     \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 100, 50)           0         \n",
      "_________________________________________________________________\n",
      "lstm_7 (LSTM)                (None, 100, 50)           20200     \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 100, 50)           0         \n",
      "_________________________________________________________________\n",
      "lstm_8 (LSTM)                (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 50,851\n",
      "Trainable params: 50,851\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Summarize the model\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "interim-introduction",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "164/164 [==============================] - 14s 58ms/step - loss: 0.5067\n",
      "Epoch 2/50\n",
      "164/164 [==============================] - 9s 57ms/step - loss: 0.8557\n",
      "Epoch 3/50\n",
      "164/164 [==============================] - 10s 60ms/step - loss: 0.9225\n",
      "Epoch 4/50\n",
      "164/164 [==============================] - 10s 61ms/step - loss: 0.7360\n",
      "Epoch 5/50\n",
      "164/164 [==============================] - 10s 60ms/step - loss: 0.6914\n",
      "Epoch 6/50\n",
      "164/164 [==============================] - 10s 62ms/step - loss: 0.6780\n",
      "Epoch 7/50\n",
      "164/164 [==============================] - 10s 60ms/step - loss: 0.6702\n",
      "Epoch 8/50\n",
      "164/164 [==============================] - 12s 71ms/step - loss: 0.6662\n",
      "Epoch 9/50\n",
      "164/164 [==============================] - 11s 65ms/step - loss: 0.6644\n",
      "Epoch 10/50\n",
      "164/164 [==============================] - 11s 69ms/step - loss: 0.6618\n",
      "Epoch 11/50\n",
      "164/164 [==============================] - 19s 119ms/step - loss: 0.6612\n",
      "Epoch 12/50\n",
      "164/164 [==============================] - 9s 58ms/step - loss: 0.6588\n",
      "Epoch 13/50\n",
      "164/164 [==============================] - 11s 65ms/step - loss: 0.6568\n",
      "Epoch 14/50\n",
      "164/164 [==============================] - 16s 95ms/step - loss: 0.6557\n",
      "Epoch 15/50\n",
      "164/164 [==============================] - 15s 90ms/step - loss: 0.6540\n",
      "Epoch 16/50\n",
      "164/164 [==============================] - 12s 75ms/step - loss: 0.6522\n",
      "Epoch 17/50\n",
      "164/164 [==============================] - 12s 74ms/step - loss: 0.6512\n",
      "Epoch 18/50\n",
      "164/164 [==============================] - 10s 59ms/step - loss: 0.6503\n",
      "Epoch 19/50\n",
      "164/164 [==============================] - 13s 78ms/step - loss: 0.6491\n",
      "Epoch 20/50\n",
      "164/164 [==============================] - 14s 85ms/step - loss: 0.6482\n",
      "Epoch 21/50\n",
      "164/164 [==============================] - 10s 61ms/step - loss: 0.6471\n",
      "Epoch 22/50\n",
      "164/164 [==============================] - 10s 62ms/step - loss: 0.6461\n",
      "Epoch 23/50\n",
      "164/164 [==============================] - 11s 64ms/step - loss: 0.6451\n",
      "Epoch 24/50\n",
      "164/164 [==============================] - 10s 61ms/step - loss: 0.6445\n",
      "Epoch 25/50\n",
      "164/164 [==============================] - 10s 59ms/step - loss: 0.6438\n",
      "Epoch 26/50\n",
      "164/164 [==============================] - 10s 62ms/step - loss: 0.6430\n",
      "Epoch 27/50\n",
      "164/164 [==============================] - 10s 63ms/step - loss: 0.6423\n",
      "Epoch 28/50\n",
      "164/164 [==============================] - 10s 62ms/step - loss: 0.6417\n",
      "Epoch 29/50\n",
      "164/164 [==============================] - 11s 65ms/step - loss: 0.6413\n",
      "Epoch 30/50\n",
      "164/164 [==============================] - 10s 63ms/step - loss: 0.6410\n",
      "Epoch 31/50\n",
      "164/164 [==============================] - 10s 60ms/step - loss: 0.6406\n",
      "Epoch 32/50\n",
      "164/164 [==============================] - 10s 63ms/step - loss: 0.6402\n",
      "Epoch 33/50\n",
      "164/164 [==============================] - 10s 62ms/step - loss: 0.6398\n",
      "Epoch 34/50\n",
      "164/164 [==============================] - 10s 59ms/step - loss: 0.6395\n",
      "Epoch 35/50\n",
      "164/164 [==============================] - 10s 62ms/step - loss: 0.6392\n",
      "Epoch 36/50\n",
      "164/164 [==============================] - 11s 66ms/step - loss: 0.6390\n",
      "Epoch 37/50\n",
      "164/164 [==============================] - 10s 63ms/step - loss: 0.6387\n",
      "Epoch 38/50\n",
      "164/164 [==============================] - 10s 61ms/step - loss: 0.6386\n",
      "Epoch 39/50\n",
      "164/164 [==============================] - 10s 61ms/step - loss: 0.6384\n",
      "Epoch 40/50\n",
      "164/164 [==============================] - 10s 63ms/step - loss: 0.6382\n",
      "Epoch 41/50\n",
      "164/164 [==============================] - 10s 61ms/step - loss: 0.6380\n",
      "Epoch 42/50\n",
      "164/164 [==============================] - 10s 62ms/step - loss: 0.6379\n",
      "Epoch 43/50\n",
      "164/164 [==============================] - 11s 64ms/step - loss: 0.6378\n",
      "Epoch 44/50\n",
      "164/164 [==============================] - 10s 60ms/step - loss: 0.6377\n",
      "Epoch 45/50\n",
      "164/164 [==============================] - 10s 60ms/step - loss: 0.6376\n",
      "Epoch 46/50\n",
      "164/164 [==============================] - 10s 63ms/step - loss: 0.6375\n",
      "Epoch 47/50\n",
      "164/164 [==============================] - 10s 62ms/step - loss: 0.6374\n",
      "Epoch 48/50\n",
      "164/164 [==============================] - 10s 64ms/step - loss: 0.6373\n",
      "Epoch 49/50\n",
      "164/164 [==============================] - 11s 65ms/step - loss: 0.6373\n",
      "Epoch 50/50\n",
      "164/164 [==============================] - 10s 61ms/step - loss: 0.6372\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f90bfdb6400>"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model\n",
    "model.fit(X_train, y_train, epochs=50, shuffle=False, batch_size=5, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "international-armstrong",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 1s 19ms/step - loss: 0.7415\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.74153733253479"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "acknowledged-nursing",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predictions\n",
    "predicted = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "taken-health",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recover the original prices instead of the scaled version\n",
    "predicted_prices = scaler.inverse_transform(predicted)\n",
    "real_prices = scaler.inverse_transform(y_test.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "thermal-demonstration",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Real</th>\n",
       "      <th>Predicted</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2019-09-30</th>\n",
       "      <td>210.589996</td>\n",
       "      <td>151.528366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-10-01</th>\n",
       "      <td>208.320007</td>\n",
       "      <td>151.528366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-10-02</th>\n",
       "      <td>206.880005</td>\n",
       "      <td>151.528366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-10-03</th>\n",
       "      <td>207.699997</td>\n",
       "      <td>151.528366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-10-04</th>\n",
       "      <td>209.960007</td>\n",
       "      <td>151.528366</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Real   Predicted\n",
       "Date                              \n",
       "2019-09-30  210.589996  151.528366\n",
       "2019-10-01  208.320007  151.528366\n",
       "2019-10-02  206.880005  151.528366\n",
       "2019-10-03  207.699997  151.528366\n",
       "2019-10-04  209.960007  151.528366"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Comparing Real and Predicted values\n",
    "stockd = pd.DataFrame({\n",
    "    \"Real\": real_prices.ravel(),\n",
    "    \"Predicted\": predicted_prices.ravel()\n",
    "    }, index = stockdf.index[-len(real_prices): ]) \n",
    "stockd.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "confused-directory",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {},
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.holoviews_exec.v0+json": "",
      "text/html": [
       "<div id='1823'>\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "  <div class=\"bk-root\" id=\"f0a2ecb0-3db5-4e93-97f1-52ba81d674f7\" data-root-id=\"1823\"></div>\n",
       "</div>\n",
       "<script type=\"application/javascript\">(function(root) {\n",
       "  function embed_document(root) {\n",
       "    var docs_json = {\"5f34d0c8-9086-4d8a-9d4a-f49f2bb1a9aa\":{\"roots\":{\"references\":[{\"attributes\":{},\"id\":\"1848\",\"type\":\"WheelZoomTool\"},{\"attributes\":{\"mantissas\":[1,2,5],\"max_interval\":500.0,\"num_minor_ticks\":0},\"id\":\"1878\",\"type\":\"AdaptiveTicker\"},{\"attributes\":{\"base\":60,\"mantissas\":[1,2,5,10,15,20,30],\"max_interval\":1800000.0,\"min_interval\":1000.0,\"num_minor_ticks\":0},\"id\":\"1879\",\"type\":\"AdaptiveTicker\"},{\"attributes\":{\"data\":{\"Date\":{\"__ndarray__\":\"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\",\"dtype\":\"float64\",\"order\":\"little\",\"shape\":[351]},\"Variable\":[\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\"],\"value\":{\"__ndarray__\":\"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\",\"dtype\":\"float64\",\"order\":\"little\",\"shape\":[351]}},\"selected\":{\"id\":\"1864\"},\"selection_policy\":{\"id\":\"1877\"}},\"id\":\"1863\",\"type\":\"ColumnDataSource\"},{\"attributes\":{},\"id\":\"1847\",\"type\":\"PanTool\"},{\"attributes\":{\"active_drag\":\"auto\",\"active_inspect\":\"auto\",\"active_multi\":null,\"active_scroll\":\"auto\",\"active_tap\":\"auto\",\"tools\":[{\"id\":\"1827\"},{\"id\":\"1846\"},{\"id\":\"1847\"},{\"id\":\"1848\"},{\"id\":\"1849\"},{\"id\":\"1850\"}]},\"id\":\"1852\",\"type\":\"Toolbar\"},{\"attributes\":{\"days\":[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31]},\"id\":\"1881\",\"type\":\"DaysTicker\"},{\"attributes\":{},\"id\":\"1846\",\"type\":\"SaveTool\"},{\"attributes\":{\"data\":{\"Date\":{\"__ndarray__\":\"AADAd/fXdkIAAIDdSdh2QgAAQEOc2HZCAAAAqe7YdkIAAMAOQdl2QgAAAEA42nZCAADApYradkIAAIAL3dp2QgAAQHEv23ZCAAAA14HbdkIAAEAIedx2QgAAAG7L3HZCAADA0x3ddkIAAIA5cN12QgAAQJ/C3XZCAACA0LnedkIAAEA2DN92QgAAAJxe33ZCAADAAbHfdkIAAIBnA+B2QgAAwJj64HZCAACA/kzhdkIAAEBkn+F2QgAAAMrx4XZCAADAL0TidkIAAABhO+N2QgAAwMaN43ZCAACALODjdkIAAECSMuR2QgAAAPiE5HZCAABAKXzldkIAAACPzuV2QgAAwPQg5nZCAACAWnPmdkIAAEDAxeZ2QgAAgPG853ZCAABAVw/odkIAAAC9Yeh2QgAAwCK06HZCAACAiAbpdkIAAMC5/el2QgAAgB9Q6nZCAABAhaLqdkIAAMBQR+t2QgAAAII+7HZCAADA55DsdkIAAIBN4+x2QgAAQLM17XZCAAAAGYjtdkIAAEBKf+52QgAAALDR7nZCAADAFSTvdkIAAIB7du92QgAAQOHI73ZCAACAEsDwdkIAAEB4EvF2QgAAAN5k8XZCAADAQ7fxdkIAAICpCfJ2QgAAwNoA83ZCAACAQFPzdkIAAAAM+PN2QgAAwHFK9HZCAAAAo0H1dkIAAMAIlPV2QgAAQNQ49nZCAAAAOov2dkIAAEBrgvd2QgAAANHU93ZCAADANif4dkIAAICcefh2QgAAQALM+HZCAACAM8P5dkIAAECZFfp2QgAAAP9n+nZCAADAZLr6dkIAAIDKDPt2QgAAgGFW/HZCAABAx6j8dkIAAAAt+/x2QgAAwJJN/XZCAAAAxET+dkIAAMApl/52QgAAgI/p/nZCAABA9Tv/dkIAAABbjv92QgAAQIyFAHdCAAAA8tcAd0IAAMBXKgF3QgAAgL18AXdCAABAI88Bd0IAAIBUxgJ3QgAAQLoYA3dCAAAAIGsDd0IAAMCFvQN3QgAAgOsPBHdCAACAglkFd0IAAEDoqwV3QgAAAE7+BXdCAADAs1AGd0IAAADlRwd3QgAAwEqaB3dCAACAsOwHd0IAAEAWPwh3QgAAAHyRCHdCAABArYgJd0IAAAAT2wl3QgAAwHgtCndCAACA3n8Kd0IAAEBE0gp3QgAAgHXJC3dCAABA2xsMd0IAAABBbgx3QgAAwKbADHdCAACADBMNd0IAAMA9Cg53QgAAgKNcDndCAABACa8Od0IAAABvAQ93QgAAwNRTD3dCAAAABksQd0IAAMBrnRB3QgAAgNHvEHdCAABAN0IRd0IAAACdlBF3QgAAQM6LEndCAAAANN4Sd0IAAMCZMBN3QgAAgP+CE3dCAABAZdUTd0IAAICWzBR3QgAAQPweFXdCAAAAYnEVd0IAAMDHwxV3QgAAwF4NF3dCAACAxF8Xd0IAAEAqshd3QgAAAJAEGHdCAADA9VYYd0IAAAAnThl3QgAAwIygGXdCAACA8vIZd0IAAEBYRRp3QgAAAL6XGndCAABA744bd0IAAABV4Rt3QgAAwLozHHdCAACAIIYcd0IAAECG2Bx3QgAAgLfPHXdCAABAHSIed0IAAACDdB53QgAAwOjGHndCAACAThkfd0IAAMB/ECB3QgAAgOViIHdCAABAS7Ugd0IAAACxByF3QgAAwBZaIXdCAAAASFEid0IAAMCtoyJ3QgAAgBP2IndCAABAeUgjd0IAAADfmiN3QgAAAHbkJHdCAADA2zYld0IAAIBBiSV3QgAAQKfbJXdCAACA2NImd0IAAEA+JSd3QgAAAKR3J3dCAADACcond0IAAIBvHCh3QgAAwKATKXdCAACABmYpd0IAAEBsuCl3QgAAANIKKndCAADAN10qd0IAAABpVCt3QgAAwM6mK3dCAACANPkrd0IAAECaSyx3QgAAAACeLHdCAABAMZUtd0IAAACX5y13QgAAwPw5LndCAACAYowud0IAAEDI3i53QgAAgPnVL3dCAABAXygwd0IAAADFejB3QgAAwCrNMHdCAADAwRYyd0IAAIAnaTJ3QgAAQI27MndCAAAA8w0zd0IAAMBYYDN3QgAAAIpXNHdCAADA76k0d0IAAIBV/DR3QgAAQLtONXdCAAAAIaE1d0IAAEBSmDZ3QgAAALjqNndCAADAHT03d0IAAICDjzd3QgAAQOnhN3dCAACAGtk4d0IAAECAKzl3QgAAAOZ9OXdCAADAS9A5d0IAAICxIjp3QgAAwOIZO3dCAACASGw7d0IAAECuvjt3QgAAABQRPHdCAADAeWM8d0IAAACrWj13QgAAwBCtPXdCAACAdv89d0IAAEDcUT53QgAAAEKkPndCAABAc5s/d0IAAADZ7T93QgAAwD5AQHdCAACApJJAd0IAAEAK5UB3QgAAgDvcQXdCAABAoS5Cd0IAAAAHgUJ3QgAAwGzTQndCAACA0iVDd0IAAMADHUR3QgAAgGlvRHdCAABAz8FEd0IAAAA1FEV3QgAAwJpmRXdCAADAMbBGd0IAAICXAkd3QgAAQP1UR3dCAAAAY6dHd0IAAECUnkh3QgAAAPrwSHdCAADAX0NJd0IAAIDFlUl3QgAAQCvoSXdCAACAXN9Kd0IAAEDCMUt3QgAAACiES3dCAADAjdZLd0IAAIDzKEx3QgAAwCQgTXdCAACAinJNd0IAAEDwxE13QgAAAFYXTndCAADAu2lOd0IAAADtYE93QgAAwFKzT3dCAACAuAVQd0IAAEAeWFB3QgAAAISqUHdCAABAtaFRd0IAAAAb9FF3QgAAwIBGUndCAACA5phSd0IAAEBM61J3QgAAgH3iU3dCAABA4zRUd0IAAABJh1R3QgAAwK7ZVHdCAACAFCxVd0IAAMBFI1Z3QgAAgKt1VndCAABAEchWd0IAAAB3Gld3QgAAwNxsV3dCAAAADmRYd0IAAMBztlh3QgAAgNkIWXdCAABAP1tZd0IAAAClrVl3QgAAQNakWndCAAAAPPdad0IAAMChSVt3QgAAgAecW3dCAABAbe5bd0IAAICe5Vx3QgAAQAQ4XXdCAAAAaopdd0IAAMDP3F13QgAAgDUvXndCAADAZiZfd0IAAIDMeF93QgAAQDLLX3dCAADA/W9gd0IAAAAvZ2F3QgAAwJS5YXdCAACA+gtid0IAAEBgXmJ3QgAAAMawYndCAABA96djd0IAAABd+mN3QgAAwMJMZHdCAACAKJ9kd0IAAECO8WR3QgAAgL/oZXdCAABAJTtmd0IAAACLjWZ3QgAAwPDfZndCAACAVjJnd0IAAMCHKWh3QgAAgO17aHdCAABAU85od0IAAAC5IGl3QgAAAFBqandCAADAtbxqd0IAAIAbD2t3QgAAQIFha3dCAABAGKtsd0IAAAB+/Wx3QgAAwONPbXdCAACASaJtd0IAAECv9G13QgAAgODrbndCAABARj5vd0IAAACskG93QgAAwBHjb3dCAACAdzVwd0IAAIAOf3F3QgAAQHTRcXdCAAAA2iNyd0IAAMA/dnJ3QgAAAHFtc3dCAADA1r9zd0IAAIA8EnR3QgAAQKJkdHdCAAAACLd0d0IAAEA5rnV3QgAAAJ8AdndCAADABFN2d0IAAIBqpXZ3QgAAQND3dndCAACAAe93d0IAAEBnQXh3QgAAAM2TeHdCAADAMuZ4d0IAAICYOHl3QgAAgC+CendCAABAldR6d0IAAAD7Jnt3QgAAwGB5e3dC\",\"dtype\":\"float64\",\"order\":\"little\",\"shape\":[351]},\"Variable\":[\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\"],\"value\":{\"__ndarray__\":\"Q4cXQ0OHF0NDhxdDQ4cXQ0OHF0NDhxdDQ4cXQ0OHF0NDhxdDQ4cXQ0OHF0NDhxdDQ4cXQ0OHF0NDhxdDQ4cXQ0OHF0NDhxdDQ4cXQ0OHF0NDhxdDQ4cXQ0OHF0NDhxdDQ4cXQ0OHF0NDhxdDQ4cXQ0OHF0NDhxdDQ4cXQ0OHF0NDhxdDQ4cXQ0OHF0NDhxdDQ4cXQ0OHF0NDhxdDQ4cXQ0OHF0NDhxdDQ4cXQ0OHF0NDhxdDQ4cXQ0OHF0NDhxdDQ4cXQ0OHF0NDhxdDQ4cXQ0OHF0NDhxdDQ4cXQ0OHF0NDhxdDQ4cXQ0OHF0NDhxdDQ4cXQ0OHF0NDhxdDQ4cXQ0OHF0NDhxdDQ4cXQ0OHF0NDhxdDQ4cXQ0OHF0NDhxdDQ4cXQ0OHF0NDhxdDQ4cXQ0OHF0NDhxdDQ4cXQ0OHF0NDhxdDQ4cXQ0OHF0NDhxdDQ4cXQ0OHF0NDhxdDQ4cXQ0OHF0NDhxdDQ4cXQ0OHF0NDhxdDQ4cXQ0OHF0NDhxdDQ4cXQ0OHF0NDhxdDQ4cXQ0OHF0NDhxdDQ4cXQ0OHF0NDhxdDQ4cXQ0OHF0NDhxdDQ4cXQ0OHF0NDhxdDQ4cXQ0OHF0NDhxdDQ4cXQ0OHF0NDhxdDQ4cXQ0OHF0NDhxdDQ4cXQ0OHF0NDhxdDQ4cXQ0OHF0NDhxdDQ4cXQ0OHF0NDhxdDQ4cXQ0OHF0NDhxdDQ4cXQ0OHF0NDhxdDQ4cXQ0OHF0NDhxdDQ4cXQ0OHF0NDhxdDQ4cXQ0OHF0NDhxdDQ4cXQ0OHF0NDhxdDQ4cXQ0OHF0NDhxdDQ4cXQ0OHF0NDhxdDQ4cXQ0OHF0NDhxdDQ4cXQ0OHF0NDhxdDQ4cXQ0OHF0NDhxdDQ4cXQ0OHF0NDhxdDQ4cXQ0OHF0NDhxdDQ4cXQ0OHF0NDhxdDQ4cXQ0OHF0NDhxdDQ4cXQ0OHF0NDhxdDQ4cXQ0OHF0NDhxdDQ4cXQ0OHF0NDhxdDQ4cXQ0OHF0NDhxdDQ4cXQ0OHF0NDhxdDQ4cXQ0OHF0NDhxdDQ4cXQ0OHF0NDhxdDQ4cXQ0OHF0NDhxdDQ4cXQ0OHF0NDhxdDQ4cXQ0OHF0NDhxdDQ4cXQ0OHF0NDhxdDQ4cXQ0OHF0NDhxdDQ4cXQ0OHF0NDhxdDQ4cXQ0OHF0NDhxdDQ4cXQ0OHF0NDhxdDQ4cXQ0OHF0NDhxdDQ4cXQ0OHF0NDhxdDQ4cXQ0OHF0NDhxdDQ4cXQ0OHF0NDhxdDQ4cXQ0OHF0NDhxdDQ4cXQ0OHF0NDhxdDQ4cXQ0OHF0NDhxdDQ4cXQ0OHF0NDhxdDQ4cXQ0OHF0NDhxdDQ4cXQ0OHF0NDhxdDQ4cXQ0OHF0NDhxdDQ4cXQ0OHF0NDhxdDQ4cXQ0OHF0NDhxdDQ4cXQ0OHF0NDhxdDQ4cXQ0OHF0NDhxdDQ4cXQ0OHF0NDhxdDQ4cXQ0OHF0NDhxdDQ4cXQ0OHF0NDhxdDQ4cXQ0OHF0NDhxdDQ4cXQ0OHF0NDhxdDQ4cXQ0OHF0NDhxdDQ4cXQ0OHF0NDhxdDQ4cXQ0OHF0NDhxdDQ4cXQ0OHF0NDhxdDQ4cXQ0OHF0NDhxdDQ4cXQ0OHF0NDhxdDQ4cXQ0OHF0NDhxdDQ4cXQ0OHF0NDhxdDQ4cXQ0OHF0NDhxdDQ4cXQ0OHF0NDhxdDQ4cXQ0OHF0NDhxdDQ4cXQ0OHF0NDhxdDQ4cXQ0OHF0NDhxdDQ4cXQ0OHF0NDhxdDQ4cXQ0OHF0NDhxdDQ4cXQ0OHF0NDhxdDQ4cXQ0OHF0NDhxdDQ4cXQ0OHF0NDhxdDQ4cXQ0OHF0NDhxdDQ4cXQ0OHF0NDhxdDQ4cXQ0OHF0NDhxdDQ4cXQ0OHF0NDhxdDQ4cXQ0OHF0NDhxdDQ4cXQ0OHF0NDhxdD\",\"dtype\":\"float32\",\"order\":\"little\",\"shape\":[351]}},\"selected\":{\"id\":\"1894\"},\"selection_policy\":{\"id\":\"1909\"}},\"id\":\"1893\",\"type\":\"ColumnDataSource\"},{\"attributes\":{\"base\":24,\"mantissas\":[1,2,4,6,8,12],\"max_interval\":43200000.0,\"min_interval\":3600000.0,\"num_minor_ticks\":0},\"id\":\"1880\",\"type\":\"AdaptiveTicker\"},{\"attributes\":{\"overlay\":{\"id\":\"1851\"}},\"id\":\"1849\",\"type\":\"BoxZoomTool\"},{\"attributes\":{\"months\":[0,1,2,3,4,5,6,7,8,9,10,11]},\"id\":\"1885\",\"type\":\"MonthsTicker\"},{\"attributes\":{},\"id\":\"1850\",\"type\":\"ResetTool\"},{\"attributes\":{\"months\":[0,2,4,6,8,10]},\"id\":\"1886\",\"type\":\"MonthsTicker\"},{\"attributes\":{\"days\":[1,4,7,10,13,16,19,22,25,28]},\"id\":\"1882\",\"type\":\"DaysTicker\"},{\"attributes\":{\"children\":[{\"id\":\"1824\"},{\"id\":\"1829\"},{\"id\":\"2122\"}],\"margin\":[0,0,0,0],\"name\":\"Row02448\",\"tags\":[\"embedded\"]},\"id\":\"1823\",\"type\":\"Row\"},{\"attributes\":{},\"id\":\"1861\",\"type\":\"BasicTickFormatter\"},{\"attributes\":{\"days\":[1,15]},\"id\":\"1884\",\"type\":\"DaysTicker\"},{\"attributes\":{\"line_alpha\":0.2,\"line_color\":\"#1f77b3\",\"line_width\":2,\"x\":{\"field\":\"Date\"},\"y\":{\"field\":\"value\"}},\"id\":\"1868\",\"type\":\"Line\"},{\"attributes\":{\"label\":{\"value\":\"Real\"},\"renderers\":[{\"id\":\"1869\"}]},\"id\":\"1892\",\"type\":\"LegendItem\"},{\"attributes\":{},\"id\":\"1894\",\"type\":\"Selection\"},{\"attributes\":{},\"id\":\"1859\",\"type\":\"DatetimeTickFormatter\"},{\"attributes\":{\"months\":[0,6]},\"id\":\"1888\",\"type\":\"MonthsTicker\"},{\"attributes\":{\"days\":[1,8,15,22]},\"id\":\"1883\",\"type\":\"DaysTicker\"},{\"attributes\":{},\"id\":\"1889\",\"type\":\"YearsTicker\"},{\"attributes\":{\"margin\":[5,5,5,5],\"name\":\"HSpacer02453\",\"sizing_mode\":\"stretch_width\"},\"id\":\"2122\",\"type\":\"Spacer\"},{\"attributes\":{\"source\":{\"id\":\"1863\"}},\"id\":\"1870\",\"type\":\"CDSView\"},{\"attributes\":{\"data_source\":{\"id\":\"1893\"},\"glyph\":{\"id\":\"1896\"},\"hover_glyph\":null,\"muted_glyph\":{\"id\":\"1898\"},\"nonselection_glyph\":{\"id\":\"1897\"},\"selection_glyph\":null,\"view\":{\"id\":\"1900\"}},\"id\":\"1899\",\"type\":\"GlyphRenderer\"},{\"attributes\":{\"months\":[0,4,8]},\"id\":\"1887\",\"type\":\"MonthsTicker\"},{\"attributes\":{\"line_alpha\":0.1,\"line_color\":\"#ff7e0e\",\"line_width\":2,\"x\":{\"field\":\"Date\"},\"y\":{\"field\":\"value\"}},\"id\":\"1897\",\"type\":\"Line\"},{\"attributes\":{},\"id\":\"1864\",\"type\":\"Selection\"},{\"attributes\":{},\"id\":\"1843\",\"type\":\"BasicTicker\"},{\"attributes\":{\"line_color\":\"#ff7e0e\",\"line_width\":2,\"x\":{\"field\":\"Date\"},\"y\":{\"field\":\"value\"}},\"id\":\"1896\",\"type\":\"Line\"},{\"attributes\":{\"label\":{\"value\":\"Predicted\"},\"renderers\":[{\"id\":\"1899\"}]},\"id\":\"1923\",\"type\":\"LegendItem\"},{\"attributes\":{\"end\":225.14600372314453,\"reset_end\":225.14600372314453,\"reset_start\":123.31400299072266,\"start\":123.31400299072266,\"tags\":[[[\"value\",\"value\",null]]]},\"id\":\"1826\",\"type\":\"Range1d\"},{\"attributes\":{\"line_alpha\":0.2,\"line_color\":\"#ff7e0e\",\"line_width\":2,\"x\":{\"field\":\"Date\"},\"y\":{\"field\":\"value\"}},\"id\":\"1898\",\"type\":\"Line\"},{\"attributes\":{\"click_policy\":\"mute\",\"items\":[{\"id\":\"1892\"},{\"id\":\"1923\"}],\"location\":[0,0],\"title\":\"Variable\"},\"id\":\"1891\",\"type\":\"Legend\"},{\"attributes\":{\"text\":\"Real vs Predicted Stock Price\",\"text_color\":{\"value\":\"black\"},\"text_font_size\":{\"value\":\"12pt\"}},\"id\":\"1830\",\"type\":\"Title\"},{\"attributes\":{},\"id\":\"1834\",\"type\":\"LinearScale\"},{\"attributes\":{\"source\":{\"id\":\"1893\"}},\"id\":\"1900\",\"type\":\"CDSView\"},{\"attributes\":{\"axis\":{\"id\":\"1838\"},\"grid_line_color\":null,\"ticker\":null},\"id\":\"1841\",\"type\":\"Grid\"},{\"attributes\":{\"data_source\":{\"id\":\"1863\"},\"glyph\":{\"id\":\"1866\"},\"hover_glyph\":null,\"muted_glyph\":{\"id\":\"1868\"},\"nonselection_glyph\":{\"id\":\"1867\"},\"selection_glyph\":null,\"view\":{\"id\":\"1870\"}},\"id\":\"1869\",\"type\":\"GlyphRenderer\"},{\"attributes\":{\"margin\":[5,5,5,5],\"name\":\"HSpacer02452\",\"sizing_mode\":\"stretch_width\"},\"id\":\"1824\",\"type\":\"Spacer\"},{\"attributes\":{\"bottom_units\":\"screen\",\"fill_alpha\":0.5,\"fill_color\":\"lightgrey\",\"left_units\":\"screen\",\"level\":\"overlay\",\"line_alpha\":1.0,\"line_color\":\"black\",\"line_dash\":[4,4],\"line_width\":2,\"right_units\":\"screen\",\"top_units\":\"screen\"},\"id\":\"1851\",\"type\":\"BoxAnnotation\"},{\"attributes\":{\"end\":1613692800000.0,\"reset_end\":1613692800000.0,\"reset_start\":1569801600000.0,\"start\":1569801600000.0,\"tags\":[[[\"Date\",\"Date\",null]]]},\"id\":\"1825\",\"type\":\"Range1d\"},{\"attributes\":{\"axis_label\":\"Real\",\"bounds\":\"auto\",\"formatter\":{\"id\":\"1859\"},\"major_label_orientation\":\"horizontal\",\"ticker\":{\"id\":\"1839\"}},\"id\":\"1838\",\"type\":\"DatetimeAxis\"},{\"attributes\":{\"axis\":{\"id\":\"1842\"},\"dimension\":1,\"grid_line_color\":null,\"ticker\":null},\"id\":\"1845\",\"type\":\"Grid\"},{\"attributes\":{\"axis_label\":\"Predicted\",\"bounds\":\"auto\",\"formatter\":{\"id\":\"1861\"},\"major_label_orientation\":\"horizontal\",\"ticker\":{\"id\":\"1843\"}},\"id\":\"1842\",\"type\":\"LinearAxis\"},{\"attributes\":{\"num_minor_ticks\":5,\"tickers\":[{\"id\":\"1878\"},{\"id\":\"1879\"},{\"id\":\"1880\"},{\"id\":\"1881\"},{\"id\":\"1882\"},{\"id\":\"1883\"},{\"id\":\"1884\"},{\"id\":\"1885\"},{\"id\":\"1886\"},{\"id\":\"1887\"},{\"id\":\"1888\"},{\"id\":\"1889\"}]},\"id\":\"1839\",\"type\":\"DatetimeTicker\"},{\"attributes\":{},\"id\":\"1909\",\"type\":\"UnionRenderers\"},{\"attributes\":{\"line_color\":\"#1f77b3\",\"line_width\":2,\"x\":{\"field\":\"Date\"},\"y\":{\"field\":\"value\"}},\"id\":\"1866\",\"type\":\"Line\"},{\"attributes\":{\"callback\":null,\"formatters\":{\"@{Date}\":\"datetime\"},\"renderers\":[{\"id\":\"1869\"},{\"id\":\"1899\"}],\"tags\":[\"hv_created\"],\"tooltips\":[[\"Variable\",\"@{Variable}\"],[\"Date\",\"@{Date}{%F %T}\"],[\"value\",\"@{value}\"]]},\"id\":\"1827\",\"type\":\"HoverTool\"},{\"attributes\":{\"line_alpha\":0.1,\"line_color\":\"#1f77b3\",\"line_width\":2,\"x\":{\"field\":\"Date\"},\"y\":{\"field\":\"value\"}},\"id\":\"1867\",\"type\":\"Line\"},{\"attributes\":{\"below\":[{\"id\":\"1838\"}],\"center\":[{\"id\":\"1841\"},{\"id\":\"1845\"}],\"left\":[{\"id\":\"1842\"}],\"margin\":[5,5,5,5],\"min_border_bottom\":10,\"min_border_left\":10,\"min_border_right\":10,\"min_border_top\":10,\"plot_height\":300,\"plot_width\":700,\"renderers\":[{\"id\":\"1869\"},{\"id\":\"1899\"}],\"right\":[{\"id\":\"1891\"}],\"sizing_mode\":\"fixed\",\"title\":{\"id\":\"1830\"},\"toolbar\":{\"id\":\"1852\"},\"x_range\":{\"id\":\"1825\"},\"x_scale\":{\"id\":\"1834\"},\"y_range\":{\"id\":\"1826\"},\"y_scale\":{\"id\":\"1836\"}},\"id\":\"1829\",\"subtype\":\"Figure\",\"type\":\"Plot\"},{\"attributes\":{},\"id\":\"1877\",\"type\":\"UnionRenderers\"},{\"attributes\":{},\"id\":\"1836\",\"type\":\"LinearScale\"}],\"root_ids\":[\"1823\"]},\"title\":\"Bokeh Application\",\"version\":\"2.2.3\"}};\n",
       "    var render_items = [{\"docid\":\"5f34d0c8-9086-4d8a-9d4a-f49f2bb1a9aa\",\"root_ids\":[\"1823\"],\"roots\":{\"1823\":\"f0a2ecb0-3db5-4e93-97f1-52ba81d674f7\"}}];\n",
       "    root.Bokeh.embed.embed_items_notebook(docs_json, render_items);\n",
       "  }\n",
       "  if (root.Bokeh !== undefined && root.Bokeh.Panel !== undefined) {\n",
       "    embed_document(root);\n",
       "  } else {\n",
       "    var attempts = 0;\n",
       "    var timer = setInterval(function(root) {\n",
       "      if (root.Bokeh !== undefined && root.Bokeh.Panel !== undefined) {\n",
       "        clearInterval(timer);\n",
       "        embed_document(root);\n",
       "      } else if (document.readyState == \"complete\") {\n",
       "        attempts++;\n",
       "        if (attempts > 100) {\n",
       "          clearInterval(timer);\n",
       "          console.log(\"Bokeh: ERROR: Unable to run BokehJS code because BokehJS library is missing\");\n",
       "        }\n",
       "      }\n",
       "    }, 10, root)\n",
       "  }\n",
       "})(window);</script>"
      ],
      "text/plain": [
       ":NdOverlay   [Variable]\n",
       "   :Curve   [Date]   (value)"
      ]
     },
     "execution_count": 83,
     "metadata": {
      "application/vnd.holoviews_exec.v0+json": {
       "id": "1823"
      }
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Plot the real vs predicted values as a line chart\n",
    "stockd.hvplot(title=\"Real vs Predicted Stock Price\", xlabel=\"Real\", ylabel=\"Predicted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "announced-trick",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.08208880658954279"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Printing metrics\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "y_pred = model.predict(X_test)\n",
    "mean_squared_error(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "immediate-potential",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSTM is 0.2865114423361531.\n"
     ]
    }
   ],
   "source": [
    "print(f\"LSTM is {rms}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "imposed-tourism",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
